{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install striprtf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pETPr_6kJ1d",
        "outputId": "4dab7d95-8f3a-48af-dbf2-9278f2f8da12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting striprtf\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf\n",
            "Successfully installed striprtf-0.0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 1: LOAD DATA AND READ TARGET AND TYPE OF REGRESSION"
      ],
      "metadata": {
        "id": "wWN_pzXnlIPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_rtf_file(file_path):\n",
        "    from striprtf.striprtf import rtf_to_text\n",
        "    with open(file_path, 'r') as file:\n",
        "        rtf_content = file.read()\n",
        "    return rtf_to_text(rtf_content)"
      ],
      "metadata": {
        "id": "R4RzeP1XkKiA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_parse_json(file_path):\n",
        "    import json\n",
        "    text = read_rtf_file(file_path)\n",
        "    json_data = json.loads(text)\n",
        "    target_details = json_data.get('design_state_data', {}).get('target', {})\n",
        "    prediction_type = target_details.get('prediction_type', 'Unknown')\n",
        "    target_variable = target_details.get('target', 'No target specified')\n",
        "    regression_type = target_details.get('type', 'No regression type specified')\n",
        "\n",
        "    return prediction_type, target_variable, regression_type, json_data"
      ],
      "metadata": {
        "id": "Juc7T7TgkYGm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'algoparams_from_ui.json.rtf'\n",
        "prediction_type, target_variable, regression_type,  json_data = load_and_parse_json(file_path)\n",
        "print(\"Prediction Type:\", prediction_type)\n",
        "print(\"Target Variable:\", target_variable)\n",
        "print(\"Regression Type:\", regression_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTzBmgFQtD3Q",
        "outputId": "c79e7d88-df0d-4c9b-9eb8-02bbae9216d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Type: Regression\n",
            "Target Variable: petal_width\n",
            "Regression Type: regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 2: IMPUTATION"
      ],
      "metadata": {
        "id": "IuAUIEh-mlM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_apply_imputation(csv_file_path, json_data):\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    feature_handling = json_data.get('design_state_data', {}).get('feature_handling', {})\n",
        "    features_imputation = {}\n",
        "    for feature, details in feature_handling.items():\n",
        "        if details.get('is_selected', False):\n",
        "            impute_info = details.get('feature_details', {}).get('impute_with', 'default_strategy')\n",
        "            impute_value = details.get('feature_details', {}).get('impute_value', None)\n",
        "            features_imputation[feature] = {'impute_with': impute_info, 'impute_value': impute_value}\n",
        "\n",
        "    for feature, details in features_imputation.items():\n",
        "        if details['impute_with'] == 'Average of values':\n",
        "            print(f\"Applying mean imputation to {feature}\")\n",
        "            df[feature].fillna(df[feature].mean(), inplace=True)\n",
        "        elif details['impute_with'] == 'custom' and details['impute_value'] is not None:\n",
        "            print(f\"Applying custom imputation with value {details['impute_value']} to {feature}\")\n",
        "            df[feature].fillna(details['impute_value'], inplace=True)\n",
        "        elif details['impute_with'] == 'default_strategy':\n",
        "            print(f\"Applying mode imputation to {feature}\")\n",
        "            df[feature].fillna(df[feature].mode()[0], inplace=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "950h5gMMkk64"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = 'iris.csv'\n",
        "df_processed = load_data_apply_imputation(csv_file_path, json_data)\n",
        "print(df_processed.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2RO2OBOkpUE",
        "outputId": "8c321cce-b67d-426b-c6bc-2a10922b22e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying mean imputation to sepal_length\n",
            "Applying custom imputation with value -1 to sepal_width\n",
            "Applying mean imputation to petal_length\n",
            "Applying custom imputation with value -2 to petal_width\n",
            "Applying mode imputation to species\n",
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_categorical(df):\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    for column in df_processed.columns:\n",
        "        if df_processed[column].dtype == 'object':\n",
        "            le = LabelEncoder()\n",
        "            df_processed[column] = le.fit_transform(df_processed[column])\n",
        "    return df_processed"
      ],
      "metadata": {
        "id": "X88jgiVplbF9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 3: FEATURE REDUCTION"
      ],
      "metadata": {
        "id": "1Eo88RhfmpN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "import numpy as np\n",
        "def apply_feature_reduction(df, json_data, target_variable):\n",
        "    df_processed = encode_categorical(df.copy())\n",
        "    reduction_config = json_data['design_state_data']['feature_reduction']\n",
        "    method = reduction_config['feature_reduction_method']\n",
        "    num_features = int(reduction_config['num_of_features_to_keep'])\n",
        "    prediction_type = json_data['design_state_data']['target']['prediction_type']\n",
        "\n",
        "    if method == 'No Reduction':\n",
        "        reduced_df = df_processed\n",
        "    elif method == 'Corr with Target':\n",
        "        numeric_df = df_processed.select_dtypes(include=[np.number])\n",
        "        correlation = numeric_df.corr()[target_variable].abs()\n",
        "        top_features = correlation.sort_values(ascending=False).index[1:num_features+1]\n",
        "        reduced_df = df[top_features]\n",
        "    elif method == 'Tree-based':\n",
        "        X = df_processed.drop(target_variable, axis=1)\n",
        "        y = df_processed[target_variable]\n",
        "        tree_model = RandomForestRegressor(n_estimators=int(reduction_config['num_of_trees']), max_depth=int(reduction_config['depth_of_trees']))\n",
        "        tree_model.fit(X, y)\n",
        "        importances = tree_model.feature_importances_\n",
        "        top_indices = np.argsort(importances)[::-1][:num_features]\n",
        "        reduced_df = df_processed[df.columns[top_indices]]\n",
        "    elif method == 'PCA':\n",
        "        numeric_df = df_processed.select_dtypes(include=[np.number])\n",
        "        pca = PCA(n_components=num_features)\n",
        "        principal_components = pca.fit_transform(numeric_df.drop(target_variable, axis=1))\n",
        "        reduced_df = pd.DataFrame(data=principal_components, columns=[f'PC{i+1}' for i in range(num_features)])\n",
        "\n",
        "    return reduced_df"
      ],
      "metadata": {
        "id": "v-E5VPLglxEe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_df = apply_feature_reduction(df_processed, json_data, target_variable)\n",
        "print(reduced_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Wd3ERbl8fk",
        "outputId": "ec3f4174-428f-4b2f-b978-80a002195c99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   petal_width  petal_length  sepal_width  sepal_length\n",
            "0          0.2           1.4          3.5           5.1\n",
            "1          0.2           1.4          3.0           4.9\n",
            "2          0.2           1.3          3.2           4.7\n",
            "3          0.2           1.5          3.1           4.6\n",
            "4          0.2           1.4          3.6           5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 4: MODEL INITIALIZATION"
      ],
      "metadata": {
        "id": "OtiteX5dqeGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor, ExtraTreesClassifier\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "def initialize_models(json_data):\n",
        "    model_configs = json_data['design_state_data']['algorithms']\n",
        "    models = []\n",
        "    model_classes = {\n",
        "        'RandomForestRegressor': RandomForestRegressor,\n",
        "        'RandomForestClassifier': RandomForestClassifier,\n",
        "        'GBTClassifier': GradientBoostingClassifier,\n",
        "        'GBTRegressor':  GradientBoostingRegressor,\n",
        "        'LinearRegression': LinearRegression,\n",
        "        'LogisticRegression': LogisticRegression,\n",
        "        'RidgeRegression': Ridge,\n",
        "        'LassoRegression': Lasso,\n",
        "        'ElasticNetRegression': ElasticNet,\n",
        "        'xg_boost': XGBRegressor,\n",
        "        'DecisionTreeRegressor': DecisionTreeRegressor,\n",
        "        'DecisionTreeClassifier': DecisionTreeClassifier,\n",
        "        'SVM': SVC,\n",
        "        'SGD': SGDClassifier,\n",
        "        'KNN': KNeighborsClassifier,\n",
        "        'extra_random_trees': ExtraTreesClassifier,\n",
        "        'neural_network': MLPClassifier\n",
        "         }\n",
        "\n",
        "    for model_name, config in model_configs.items():\n",
        "        if config['is_selected']:\n",
        "            model_class = model_classes.get(model_name)\n",
        "            if model_class:\n",
        "                param_grid = {}\n",
        "                if model_name == 'RandomForestRegressor':\n",
        "                    param_grid['n_estimators'] = list(range(config['min_trees'], config['max_trees'] + 1))\n",
        "                    param_grid['max_depth'] = list(range(config['min_depth'], config['max_depth'] + 1))\n",
        "                    param_grid['min_samples_leaf'] = list(range(config['min_samples_per_leaf_min_value'], config['min_samples_per_leaf_max_value'] + 1))\n",
        "\n",
        "                # Parameters for other models\n",
        "\n",
        "                model_info = {\n",
        "                    'model': model_class(),\n",
        "                    'params': param_grid\n",
        "                }\n",
        "                models.append(model_info)\n",
        "    return models\n"
      ],
      "metadata": {
        "id": "9r3K91yLmKls"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = initialize_models(json_data)\n",
        "for model in models:\n",
        "    print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf0jN0FprVql",
        "outputId": "0b7ff81e-ec90-48cb-a70b-8f0b821be04f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model': RandomForestRegressor(), 'params': {'n_estimators': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'max_depth': [20, 21, 22, 23, 24, 25], 'min_samples_leaf': [5, 6, 7, 8, 9, 10]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 5: HYPERPARAMETER TUNING\n"
      ],
      "metadata": {
        "id": "ZcSvHLFIqyqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(reduced_df, target_variable):\n",
        "    y = reduced_df[target_variable]\n",
        "    X = reduced_df.drop(target_variable, axis=1)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "ULQ8MFY8rYtx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "def fit_predict_models(models,json_data, df, target_variable):\n",
        "    X, y = preprocess_data(df, target_variable)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for model_config in models:\n",
        "        model = model_config['model']\n",
        "        param_grid = model_config['params']\n",
        "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_model = grid_search.best_estimator_\n",
        "        predictions = best_model.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(y_test, predictions)\n",
        "        r2 = r2_score(y_test, predictions)\n",
        "        results.append((type(best_model).__name__, 'MSE', mse))\n",
        "        results.append((type(best_model).__name__, 'RMSE', rmse))\n",
        "        results.append((type(best_model).__name__, 'MAE', mae))\n",
        "        results.append((type(best_model).__name__, 'R2', r2))\n",
        "\n",
        "        print(f\"Best parameters for {type(best_model).__name__}: {grid_search.best_params_}\")\n",
        "        print(f\"Evaluation metrics for {type(best_model).__name__}: MSE={mse}, RMSE={rmse}, MAE={mae}, R2={r2}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "ckEpjkYLpctz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 6: RESULTS"
      ],
      "metadata": {
        "id": "M3e3VJwRrJgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = initialize_models(json_data)\n",
        "fit_predict_results = fit_predict_models(models, json_data, reduced_df, target_variable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr4ex0FjqTeW",
        "outputId": "10b6f9e0-e61c-4c0b-f768-28fbd0ba83d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForestRegressor: {'max_depth': 24, 'min_samples_leaf': 8, 'n_estimators': 15}\n",
            "Evaluation metrics for RandomForestRegressor: MSE=0.0350368350359278, RMSE=0.18718128922498584, MAE=0.1494706710275019, R2=0.9448807853094181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQYgcs9Dv3A9"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}